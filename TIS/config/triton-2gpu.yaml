apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: llama-3-8b
  namespace: llama
  annotations:
    "sidecar.istio.io/inject": "true"
spec:
  predictor:
    model:
      modelFormat:
        name: triton
        version: "2"
      runtime: triton-trtllm
#      storageUri: pvc://llm-data-pvc/
      volumeMounts:
        - name: llm-data-pvc
          mountPath: /mnt
          readOnly: false
      name: kserve-container
      resources:
        limits:
          nvidia.com/v100: "2"
      command:
        - "/bin/bash"
        - "-c"
        - "/code/REServe/Initializer/main.sh run --tp 2"
    volumes:
      - name: llm-data-pvc
        persistentVolumeClaim:
          claimName: llm-data-pvc
          readOnly: false
#      - name: secret-volume
#        secret:
#          secretName: rook-ceph-admin-keyring